# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.14.6
#   kernelspec:
#     display_name: venv-somalia-gcp
#     language: python
#     name: venv-somalia-gcp
# ---

# %% [markdown]
# # Model outputs
#
# <div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #31708f; background-color: #d9edf7; border-color: #bce8f1;">
# Before running this project ensure that the correct kernel is selected (top right). The default project environment name is `venv-somalia-gcp`.
# </div>
#
# This notebook utilises `.npy` and `.csv` files in the `outputs` folder and `hdf5` files in the `models` folder for `runid's` generated by `3_model_train_notebook.py` in order to see the results of model runs. You can also get `runid's` that other colleagues generated on GCP by using the `bucket_import_notebook.py`.
# %% [markdown]
# ## Set-up

# %% [markdown]
# ### segmentation models framework

# %%
# %env SM_FRAMEWORK = tf.keras

# %% [markdown]
# ### Import libraries & functions

# %%
import keras
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

import h5py
from pathlib import Path
from keras.metrics import MeanIoU
import tensorflow as tf


# %%
from functions_library import get_folder_paths
from loss_functions import get_combined_loss
from multi_class_unet_model_build import jacard_coef
from model_outputs_functions import (
    calculate_metrics,
    calculate_tile_metrics,
    plot_confusion_matrix,
)

# %% [markdown]
# ### File directories

# %%
folder_dict = get_folder_paths()
# set model and output directories
models_dir = Path(folder_dict["models_dir"])
outputs_dir = Path(folder_dict["outputs_dir"])

# %% [markdown]
# ### Set runid

# %%
# Set runid for outputs
runid = "qa_testing_2024-01-17_0920"


# %% [markdown]
# ## Import data

# %% [markdown]
# ### Model conditions

# %%
# set model input read depending on when model was run
old_model = True
if old_model:
    model_filename = f"{runid}.hdf5"
    model_phase = h5py.File(models_dir.joinpath(model_filename), "r")
else:
    model_filename = runid
    model_phase = models_dir.joinpath(model_filename)


# %% [markdown]
# ### History (epochs)

# %%
csv_filename = f"{runid}.csv"
history = pd.read_csv(outputs_dir.joinpath(csv_filename))

# %% [markdown]
# ### Predictions

# %%
X_test_filename = f"{runid}_xtest.npy"
y_pred_filename = f"{runid}_ypred.npy"
y_test_filename = f"{runid}_ytest.npy"
filenames_filename = f"{runid}_filenamestest.npy"

X_test = np.load(outputs_dir.joinpath(X_test_filename))
y_pred = np.load(outputs_dir.joinpath(y_pred_filename))
y_test = np.load(outputs_dir.joinpath(y_test_filename))
filenames = np.load(outputs_dir.joinpath(filenames_filename))


# %% [markdown]
# ### Set loss

# %%
# check total loss has loaded successfully
total_loss = get_combined_loss()

# %% [markdown]
# ## Load model

# %%
model = keras.models.load_model(
    model_phase,
    custom_objects={
        "dice_loss_plus_1focal_loss": total_loss,
        "dice_loss_plus_focal_loss": total_loss,
        "focal_loss": total_loss[0],
        "dice_loss": total_loss[1],
        "jacard_coef": jacard_coef,
    },
)


# %% [markdown]
# ## Group training tiles

# %%
tiles_df = (
    pd.DataFrame(filenames, columns=["tile_name"])
    .reset_index()
    .groupby("tile_name")["index"]
    .agg(index_num=lambda x: ",".join(x.astype(str)), num_count="count")
    .reset_index()
)

# %% [markdown]
# ## Training and validation changes <a name="#trainingvalidationchanges"></a>

# %%
# create plot showing training and validation loss
loss = history["loss"]
val_loss = history["val_loss"]

epochs = range(1, len(history.loss) + 1)

plt.plot(epochs, history.loss, "y", label="Training loss")
plt.plot(epochs, history.val_loss, "r", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# %%
# create plot showing the IoU over time
acc = history["jacard_coef"]
val_acc = history["val_jacard_coef"]

plt.plot(epochs, history.accuracy, "y", label="Training IoU")
plt.plot(epochs, history.val_accuracy, "r", label="Validation IoU")
plt.title("Training and validation IoU")
plt.xlabel("Epochs")
plt.ylabel("IoU")
plt.legend()
plt.show()

# %% [markdown]
# ### Mean IoU

# %%
n_classes = y_test.shape[3]
n_classes

# %%
with tf.device("/cpu:0"):
    y_pred = model.predict(X_test)
    y_pred_argmax = np.argmax(y_pred, axis=3)
    y_test_argmax = np.argmax(y_test, axis=3)

# %%
# calculating mean IoU
with tf.device("/cpu:0"):
    IOU_keras = MeanIoU(num_classes=n_classes)
    IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())

# %% [markdown]
# ### Predications across individual validation images

# %% jupyter={"outputs_hidden": true}
test_img_number = 11
test_img = X_test[test_img_number]

# mask
ground_truth = y_test_argmax[test_img_number]

test_img_input = np.expand_dims(test_img, 0)
prediction = model.predict(test_img_input)
predicted_img = np.argmax(prediction, axis=3)[0, :, :]

# BGR to RGB
test_img = test_img[:, :, :3]
test_img = test_img[:, :, ::-1]
print(filenames[test_img_number])

# %%
plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title("Testing Image")
plt.imshow(test_img)  # [:, :, :3])
plt.subplot(232)
plt.title("Testing Label")
plt.imshow(ground_truth)
plt.subplot(233)
plt.title("Prediction on test image")
plt.imshow(predicted_img)
plt.show()

# %% [markdown]
# ## Confusion Matrix

# %%
class_names = ["Background", "Building", "Tent", "Building_border", "Tent_border"]

# %% [markdown]
# ### Whole run metrics

# %%
with tf.device("/cpu:0"):
    y_true = y_test_argmax
    y_pred = model.predict(X_test)
    y_pred_arg = np.argmax(y_pred, axis=-1)


# %%
metrics_df = calculate_metrics(y_true, y_pred_arg, class_names)
metrics_df = metrics_df.set_index("Class")
metrics_df

# %% [markdown]
# ### Confusion matrix plot

# %%
plot_confusion_matrix(y_true, y_pred_arg, class_names)


# %% [markdown]
# ### Tile metrics

# %%
tile_metrics_df = calculate_tile_metrics(y_pred, y_test_argmax, class_names, filenames)
tile_metrics_df = tile_metrics_df.set_index("tile")
# tile_metrics_df.to_csv(str(outputs_dir) + "/" + runid + "_tile_metrics.csv")
tile_metrics_df

# %% [markdown]
# ## Images and metrics for groups of tiles

# %%
# unique 'tile_name' values
unique_tile_names = tiles_df["tile_name"].unique()

# create a dropdown widget to select 'tile_name'
dropdown_tile_names = widgets.Dropdown(
    options=unique_tile_names, description="Select tile name:"
)

output_plot = widgets.Output()

# function to handle widget changes
def on_dropdown_change(change):
    if change["type"] == "change" and change["name"] == "value":
        selected_tile = change["new"]
        plot_images_for_tile(selected_tile)


# set up the widget event listener
dropdown_tile_names.observe(on_dropdown_change)


# %%
# plot function to filter on widget
def plot_images_for_tile(selected_tile):
    specific_tile_df = tiles_df[tiles_df["tile_name"] == selected_tile]

    num_count = specific_tile_df["num_count"].iloc[0]
    index_numbers = specific_tile_df["index_num"].iloc[0].split(",")

    if num_count > 0 and index_numbers:
        plots = []

        for i in range(min(num_count, len(index_numbers))):
            test_img_number = int(index_numbers[i])

            test_img = X_test[test_img_number]
            ground_truth = y_test_argmax[test_img_number]
            test_img_input = np.expand_dims(test_img, 0)
            prediction = model.predict(test_img_input)
            predicted_img = np.argmax(prediction, axis=3)[0, :, :]
            test_img = test_img[:, :, :3]
            test_img = test_img[:, :, ::-1]

            fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 8))
            axs[0].imshow(test_img)
            axs[0].set_title("Testing Image")

            axs[1].imshow(ground_truth)
            axs[1].set_title("Testing Label")

            axs[2].imshow(predicted_img)
            axs[2].set_title("Prediction on test image")

            plots.append(fig)

    # clear previous output and display the plots
    with output_plot:
        clear_output(wait=True)
        for plot in plots:
            display(plot)


# %%
# metrics function to filter on widget
def update_displayed_data(selected_tile):
    selected_tile_data = tile_metrics_df[tile_metrics_df.index == selected_tile]

    if not selected_tile_data.empty:
        display(selected_tile_data)


# %%
# display the dropdown widget and output area for plots
display(dropdown_tile_names)

# %% [markdown]
# ### Plots

# %%
# show plots based on dropdown
display(output_plot)

# %% [markdown]
# ### Metrics

# %%
update_displayed_data(dropdown_tile_names.value)

# %% [markdown]
# ### Polygons

# %%
import numpy as np
import rasterio
import rasterio.features


# from rasterio.features import shapes
import matplotlib.pyplot as plt
import geopandas as gpd
from shapely.geometry import Polygon

# %%
# creating masks for buildings and tents
mask_1 = (predicted_img == 1).astype(np.uint8)
mask_2 = (predicted_img == 2).astype(np.uint8)
mask_3 = (predicted_img == 3).astype(np.uint8)
mask_4 = (predicted_img == 4).astype(np.uint8)


# %%

# Define masks and shapes
masks = [mask_1, mask_2, mask_3, mask_4]
shapes = [rasterio.features.shapes(m, mask=m, connectivity=4) for m in masks]
titles = ["Buildings", "Tents", "Buildings Borders", "Tents Borders"]
edgecolors = ["red", "blue", "green", "orange"]

# Subplots
fig, axs = plt.subplots(1, 5, figsize=(25, 5))

# Original predicted_img
axs[0].imshow(
    predicted_img,
    cmap="viridis",
    extent=[0, predicted_img.shape[1], predicted_img.shape[0], 0],
)
axs[0].set_title("Predicted Image")

# Plot shapes for each mask
for i, (mask, shape, title, edgecolor) in enumerate(
    zip(masks, shapes, titles, edgecolors), start=1
):
    axs[i].imshow(
        predicted_img,
        cmap="gray",
        extent=[0, predicted_img.shape[1], predicted_img.shape[0], 0],
    )
    axs[i].set_title(title)

    for s, value in shape:
        if s["type"] == "Polygon":
            coords = np.array(s["coordinates"][0])
            axs[i].fill(coords[:, 0], coords[:, 1], edgecolor=edgecolor, fill=False)

plt.tight_layout()
plt.show()

# %%
# generate shapes for mask_1 buildings
buildings_shapes = rasterio.features.shapes(mask_1, mask=mask_1, connectivity=4)

# generate shapes for mask_2 tents
tents_shapes = rasterio.features.shapes(mask_2, mask=mask_2, connectivity=4)

# generate shapes for mask_1 buildings
buildings_borders_shapes = rasterio.features.shapes(mask_3, mask=mask_3, connectivity=4)

# generate shapes for mask_2 tents
tents_borders_shapes = rasterio.features.shapes(mask_4, mask=mask_4, connectivity=4)

# convert shapes into Shapely geometries
def shapes_to_geopandas(shapes, category):
    geometries = []
    for shape, value in shapes:
        if shape["type"] == "Polygon":
            coords = shape["coordinates"][0]
            polygon = Polygon(coords)
            geometries.append({"geometry": polygon, "type": category})
    return geometries


# convert shapes to gpds geometries
buildings_geometries = shapes_to_geopandas(buildings_shapes, "buildings")
tents_geometries = shapes_to_geopandas(tents_shapes, "tents")
buildings_borders_geometries = shapes_to_geopandas(
    buildings_borders_shapes, "building_borders"
)
tents_borders_geometries = shapes_to_geopandas(tents_borders_shapes, "tent_borders")

# create gdf
buildings_gdf = gpd.GeoDataFrame(buildings_geometries)
tents_gdf = gpd.GeoDataFrame(tents_geometries)
buildings_borders_gdf = gpd.GeoDataFrame(buildings_borders_geometries)
tents_borders_gdf = gpd.GeoDataFrame(tents_borders_geometries)

# concatenate gdfs
combined_gdf = gpd.GeoDataFrame(
    pd.concat(
        [buildings_gdf, buildings_borders_gdf, tents_gdf, tents_borders_gdf],
        ignore_index=True,
    )
)

print(combined_gdf.head())


# %%
filename = "training_data_baidoa_8_jo"
ax = combined_gdf.plot(
    column="type", categorical=True, legend=True, figsize=(8, 8), cmap="Set3"
)
ax.invert_yaxis()

plt.title(f"Outputted polgons - {filename}")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.show()

# %%
mask_dir = Path(folder_dict["training_mask_dir"])
geojson_path = mask_dir / f"{filename}.geojson"

# %%
geojson_data = gpd.read_file(geojson_path)

# %%
crs = geojson_data.crs
combined_gdf.crs = crs

# %%
merged_df = gpd.sjoin(combined_gdf, geojson_data, how="left", predicate="intersects")
